'use client';

import { useState, useEffect, useRef, useCallback } from 'react';
import {
  Box,
  Typography,
  Button,
  Paper,
  Dialog,
  DialogTitle,
  DialogContent,
  DialogActions,
  Chip,
  LinearProgress,
  CircularProgress,
  Alert,
} from '@mui/material';
import {
  Mic,
  Stop,
} from '@mui/icons-material';
import attemptService from '@/services/attemptService';
import { getAssetUrl } from '@/services/api';

export default function SpeakingQuestion({ 
  question, 
  answer,
  onAnswerChange, 
  onMoveToNextQuestion, 
  attemptId, 
  onHideHeader,
  microphoneTestCompleted = false,
  onStartMicrophoneTest,
  onCompleteMicrophoneTest,
  isPractice = false
}) {
  // Early return if no question
  if (!question) {
    return (
      <Box sx={{ p: 3, textAlign: 'center' }}>
        <Typography>ƒêang t·∫£i c√¢u h·ªèi...</Typography>
      </Box>
    );
  }
  // Modal states
  const [step, setStep] = useState('recording'); // recording only
  
  // Recording states
  const [isRecording, setIsRecording] = useState(false);
  const [recordingTime, setRecordingTime] = useState(30); // Start at 30 seconds
  const [audioBlob, setAudioBlob] = useState(null);
  const [audioUrl, setAudioUrl] = useState('');
  
  // Preparation states
  const [isPreparing, setIsPreparing] = useState(false);
  const [preparationTime, setPreparationTime] = useState(0);
  
  // Upload states
  const [isUploading, setIsUploading] = useState(false);
  const [uploadProgress, setUploadProgress] = useState(0);
  const [uploadError, setUploadError] = useState(null);
  const [uploadRetries, setUploadRetries] = useState(0);
  
  // Test tracking (removed - no longer needed)
  
  const mediaRecorderRef = useRef(null);
  const audioRef = useRef(null);
  const recordingTimerRef = useRef(null);
  const preparationTimerRef = useRef(null);
  const timeCounterRef = useRef(0);
  const MAX_UPLOAD_RETRIES = 3;

  // Parse question requirements
  const requirements = question.question_content?.requirements || {};
  const maxRecordingTime = 30; // Fixed at 30 seconds
  const preparationTimeLimit = parseInt(requirements.preparation_time) || 5; // seconds (default 5)
  const hasPreparationTime = preparationTimeLimit > 0;
  
  // Confirmation dialog state
  const [showStopConfirmation, setShowStopConfirmation] = useState(false);
  
  // Track if we should auto-start recording
  const shouldAutoStartRecordingRef = useRef(false);
  
  // Track when recording actually completes (to trigger upload)
  const recordingCompletedRef = useRef(false);

  // Check if question already has audio answer
  const hasExistingAudio = question.answer_data?.audio_url;

  // Initialize component - start with preparation or recording
  useEffect(() => {
    // If already has audio answer, don't start recording/preparation
    if (hasExistingAudio) {
      console.log('[SpeakingQuestion] Question already has audio answer, showing completed state');
      setStep('completed');
      return;
    }
    
    // Reset step and start fresh
    setStep('recording');
    
    // Start preparation or recording based on question requirements
    if (hasPreparationTime) {
      setAudioBlob(null);
      setAudioUrl('');
      setIsRecording(false);
      setIsPreparing(true);
      setPreparationTime(preparationTimeLimit);
      shouldAutoStartRecordingRef.current = false;
      // Keep header visible: onHideHeader?.(true);
    } else {
      setAudioBlob(null);
      setAudioUrl('');
      setIsRecording(false);
      setIsPreparing(false);
      shouldAutoStartRecordingRef.current = true;
      // Keep header visible: onHideHeader?.(false);
    }
  }, [question.id, hasPreparationTime, preparationTimeLimit]);

  // Reset states when question changes
  useEffect(() => {
    // Reset all states without triggering any timers or recordings
    setIsRecording(false);
    setRecordingTime(30);
    setAudioBlob(null);
    setAudioUrl('');
    setIsPreparing(false);
    setPreparationTime(0);
    setIsUploading(false);
    setUploadProgress(0);
    setUploadError(null);
    recordingCompletedRef.current = false;
    setUploadRetries(0);
    timeCounterRef.current = 30;
    setShowStopConfirmation(false);
    
    // Cleanup function for unmount
    return () => {
      // Stop any ongoing recording
      if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
        mediaRecorderRef.current.stop();
      }
      
      // Clear all timers
      if (recordingTimerRef.current) {
        clearInterval(recordingTimerRef.current);
        recordingTimerRef.current = null;
      }
      if (preparationTimerRef.current) {
        clearInterval(preparationTimerRef.current);
        preparationTimerRef.current = null;
      }
      
      // Cleanup old audio URLs to prevent memory leaks
      if (audioUrl) {
        URL.revokeObjectURL(audioUrl);
      }
    };
  }, [question.id]); // Only depend on question.id

  // Preparation timer
  useEffect(() => {
    if (!isPreparing) {
      return;
    }

    // Don't hide header - keep timer and question info visible
    // onHideHeader?.(true);
    
    preparationTimerRef.current = setInterval(() => {
      setPreparationTime((prev) => {
        if (prev <= 1) {
          clearInterval(preparationTimerRef.current);
          preparationTimerRef.current = null;
          setIsPreparing(false);
          // onHideHeader?.(false);
          // Mark that we need to start recording
          shouldAutoStartRecordingRef.current = true;
          return 0;
        }
        return prev - 1;
      });
    }, 1000);

    return () => {
      if (preparationTimerRef.current) {
        clearInterval(preparationTimerRef.current);
        preparationTimerRef.current = null;
      }
    };
  }, [isPreparing]); // Remove unnecessary deps

  // Recording timer (30 seconds)
  useEffect(() => {
    if (!isRecording) {
      if (recordingTimerRef.current) {
        clearInterval(recordingTimerRef.current);
        recordingTimerRef.current = null;
      }
      return;
    }

    recordingTimerRef.current = setInterval(() => {
      setRecordingTime((prev) => {
        const newTime = prev - 1;
        timeCounterRef.current = newTime;
        
        // Auto-stop at 0 seconds
        if (newTime <= 0) {
          if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
            mediaRecorderRef.current.stop();
          }
          setIsRecording(false);
          if (recordingTimerRef.current) {
            clearInterval(recordingTimerRef.current);
            recordingTimerRef.current = null;
          }
          return 0;
        }
        
        return newTime;
      });
    }, 1000);

    return () => {
      if (recordingTimerRef.current) {
        clearInterval(recordingTimerRef.current);
        recordingTimerRef.current = null;
      }
    };
  }, [isRecording, question.id]);

  // Removed microphone test functions - no longer needed

  const startRecording = useCallback(async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mediaRecorder = new MediaRecorder(stream);
      const chunks = [];
      
      mediaRecorder.ondataavailable = (event) => {
        chunks.push(event.data);
      };
      
      mediaRecorder.onstop = async () => {
        const mimeType = MediaRecorder.isTypeSupported('audio/webm;codecs=opus') 
          ? 'audio/webm;codecs=opus' 
          : 'audio/webm';
        const blob = new Blob(chunks, { type: mimeType });
        const url = URL.createObjectURL(blob);
        
        recordingCompletedRef.current = true;
        setAudioBlob(blob);
        setAudioUrl(url);
        
        stream.getTracks().forEach(track => track.stop());
      };
      
      mediaRecorderRef.current = mediaRecorder;
      mediaRecorder.start();
      setIsRecording(true);
      setRecordingTime(30);
      timeCounterRef.current = 30;
      
    } catch (error) {
      console.error('[SpeakingQuestion] Microphone error:', error.message);
      alert('Kh√¥ng th·ªÉ truy c·∫≠p microphone. Vui l√≤ng ki·ªÉm tra quy·ªÅn truy c·∫≠p.');
    }
  }, []);

  // Define uploadAudioToBackend BEFORE effects that use it
  const uploadAudioToBackend = useCallback(async (audioBlob, duration) => {
    if (uploadRetries === 0) {
      setUploadError(null);
    }
    
    try {
      setIsUploading(true);
      setUploadProgress(0);
      
      if (!attemptId) {
        throw new Error('Kh√¥ng t√¨m th·∫•y ID n·ªôp b√†i. Vui l√≤ng l√†m l·∫°i.');
      }
      
      if (!audioBlob || audioBlob.size === 0) {
        throw new Error('File √¢m thanh kh√¥ng h·ª£p l·ªá. Vui l√≤ng ghi √¢m l·∫°i.');
      }

      const MIN_AUDIO_SIZE = 1024; // 1KB
      const MAX_AUDIO_SIZE = 50 * 1024 * 1024; // 50MB
      
      if (audioBlob.size < MIN_AUDIO_SIZE) {
        throw new Error('T·ªáp √¢m thanh qu√° nh·ªè. Vui l√≤ng ghi √¢m l·∫°i.');
      }

      if (audioBlob.size > MAX_AUDIO_SIZE) {
        throw new Error('T·ªáp √¢m thanh qu√° l·ªõn (t·ªëi ƒëa 50MB). Vui l√≤ng ghi √¢m l·∫°i.');
      }

      console.log('[SpeakingQuestion] Uploading audio for question:', question.id, 'to attempt:', attemptId);
      
      const response = await attemptService.uploadAudioAnswer(
        attemptId,
        question.id,
        audioBlob,
        (progressEvent) => {
          const progress = Math.round((progressEvent.loaded / progressEvent.total) * 100);
          setUploadProgress(progress);
        }
      );

      if (response.data && response.data.success) {
        setIsUploading(false);
        setUploadError(null);
        setUploadRetries(0);
        
        // Notify parent component that answer has been saved
        if (onAnswerChange) {
          onAnswerChange(question.id, {
            answer_type: 'audio',
            audio_url: response.data.data.audio_url,
            duration: response.data.data.duration,
            answered_at: new Date().toISOString()
          });
          console.log('[SpeakingQuestion] Called onAnswerChange with:', { answer_type: 'audio', audio_url: response.data.data.audio_url });
        }
        
        // Auto-move to next question after 1.5 seconds
        setTimeout(() => {
          if (onMoveToNextQuestion) {
            console.log('[SpeakingQuestion] Moving to next question');
            onMoveToNextQuestion();
          }
        }, 1500);
      } else {
        throw new Error(response.data?.message || 'L·ªói t·∫£i l√™n audio');
      }
      
    } catch (error) {
      setIsUploading(false);

      let errorMsg = error.message || 'L·ªói t·∫£i l√™n audio. Vui l√≤ng th·ª≠ l·∫°i.';
      let shouldRetry = false;

      if (error.response) {
        const status = error.response.status;
        errorMsg = error.response.data?.message || errorMsg;
        shouldRetry = status >= 500 || status === 408 || status === 429;
        
        if (shouldRetry && uploadRetries < MAX_UPLOAD_RETRIES) {
          setUploadRetries(uploadRetries + 1);
          setUploadError(`L·ªói m√°y ch·ªß, ƒëang th·ª≠ l·∫°i... (L·∫ßn ${uploadRetries + 2}/${MAX_UPLOAD_RETRIES + 1})`);
          await new Promise(resolve => setTimeout(resolve, 1000 * (uploadRetries + 1)));
          return uploadAudioToBackend(audioBlob, duration);
        }
      } else if (error.message === 'timeout of 30000ms exceeded') {
        if (uploadRetries < MAX_UPLOAD_RETRIES) {
          setUploadRetries(uploadRetries + 1);
          setUploadError(`H·∫øt th·ªùi gian, ƒëang th·ª≠ l·∫°i... (L·∫ßn ${uploadRetries + 2}/${MAX_UPLOAD_RETRIES + 1})`);
          await new Promise(resolve => setTimeout(resolve, 1000 * (uploadRetries + 1)));
          return uploadAudioToBackend(audioBlob, duration);
        }
        errorMsg = 'H·∫øt th·ªùi gian t·∫£i l√™n. Vui l√≤ng ki·ªÉm tra k·∫øt n·ªëi v√† th·ª≠ l·∫°i.';
      }
      
      setUploadError(errorMsg);
      alert(`‚ùå ${errorMsg}`);
    }
  }, [question.id, attemptId, uploadRetries, onMoveToNextQuestion]);

  // Auto-upload when audioBlob is set (after recording stops)
  useEffect(() => {
    if (audioBlob && !isUploading && !uploadError && recordingCompletedRef.current) {
      console.log('[SpeakingQuestion] Auto-uploading audio blob for question:', question.id);
      recordingCompletedRef.current = false; // Reset so it only triggers once per recording
      const duration = 30 - timeCounterRef.current;
      uploadAudioToBackend(audioBlob, duration);
    }
  }, [audioBlob, isUploading, uploadError, uploadAudioToBackend, question.id]); // Add proper deps

  // Auto-start recording when conditions are met
  useEffect(() => {
    if (shouldAutoStartRecordingRef.current && 
        step === 'recording' && 
        !isRecording && 
        !isPreparing && 
        !isUploading && 
        !audioBlob) {
      
      shouldAutoStartRecordingRef.current = false;
      
      setTimeout(() => {
        startRecording();
      }, 300);
    }
  }, [step, isRecording, isPreparing, isUploading, audioBlob, question.id, startRecording]);
  
  const confirmStopRecording = () => {
    setShowStopConfirmation(false);
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop(); // This will trigger onstop event ‚Üí upload
      setIsRecording(false);
      
      if (recordingTimerRef.current) {
        clearInterval(recordingTimerRef.current);
        recordingTimerRef.current = null;
      }
    }
  };

  const formatTime = (seconds) => {
    const mins = Math.floor(seconds / 60);
    const secs = seconds % 60;
    return `${mins}:${secs.toString().padStart(2, '0')}`;
  };

  const canStopRecording = recordingTime <= 20; // Can stop after 10 seconds have elapsed (30-10=20)

  return (
    <Box>
      {/* Completed State - Show when audio already uploaded */}
      {step === 'completed' && hasExistingAudio && (
        <Box>
          <Paper sx={{ p: 3, mb: 2, textAlign: 'center', backgroundColor: 'success.light' }}>
            <Typography variant="h5" gutterBottom color="success.dark" sx={{ fontWeight: 'bold' }}>
              ‚úì ƒê√£ ho√†n th√†nh ghi √¢m
            </Typography>
            <Typography variant="body1" color="text.secondary">
              B·∫°n ƒë√£ ghi √¢m v√† n·ªôp c√¢u tr·∫£ l·ªùi cho c√¢u h·ªèi n√†y.
            </Typography>
            
            {/* Audio Player */}
            {question.answer_data?.audio_url && (
              <Box sx={{ mt: 2, mb: 2 }}>
                <audio 
                  controls 
                  style={{ width: '100%', maxWidth: '500px' }}
                  src={getAssetUrl(question.answer_data.audio_url)}
                >
                  Tr√¨nh duy·ªát kh√¥ng h·ªó tr·ª£ ph√°t audio.
                </audio>
              </Box>
            )}
            
            {question.answer_data?.transcribed_text && (
              <Paper sx={{ p: 2, mt: 2, backgroundColor: 'white' }}>
                <Typography variant="subtitle2" gutterBottom>
                  N·ªôi dung phi√™n √¢m:
                </Typography>
                <Typography variant="body2" sx={{ fontStyle: 'italic' }}>
                  "{question.answer_data.transcribed_text}"
                </Typography>
              </Paper>
            )}
            
            <Typography variant="caption" display="block" sx={{ mt: 2, color: 'text.secondary' }}>
              B·∫°n c√≥ th·ªÉ chuy·ªÉn sang c√¢u ti·∫øp theo
            </Typography>
          </Paper>
          
          {/* Show original question content */}
          <Typography variant="h6" gutterBottom>
            C√¢u h·ªèi:
          </Typography>
          <Paper sx={{ p: 2, backgroundColor: 'grey.50' }}>
            <Typography variant="body1" sx={{ lineHeight: 1.6 }}>
              {question.content}
            </Typography>
          </Paper>
        </Box>
      )}
      
      {/* Recording Step */}
      {step === 'recording' && (
        <Box>
          {/* Question Content - Always visible in recording step */}
          <Typography variant="h6" gutterBottom>
            {question.questionType?.code === 'SPEAKING_INTRO' && 'Gi·ªõi thi·ªáu b·∫£n th√¢n:'}
            {question.questionType?.code === 'SPEAKING_DESCRIPTION' && 'M√¥ t·∫£ h√¨nh ·∫£nh:'}
            {question.questionType?.code === 'SPEAKING_COMPARISON' && 'So s√°nh v√† ph√¢n t√≠ch:'}
            {question.questionType?.code === 'SPEAKING_DISCUSSION' && 'Th·∫£o lu·∫≠n ch·ªß ƒë·ªÅ:'}
            {!['SPEAKING_INTRO', 'SPEAKING_DESCRIPTION', 'SPEAKING_COMPARISON', 'SPEAKING_DISCUSSION'].includes(question.questionType?.code) && 'Ghi √¢m c√¢u tr·∫£ l·ªùi:'}
          </Typography>
          
          {/* Question Content */}
          {question.content && (
            <Paper sx={{ p: 2, mb: 2, backgroundColor: 'grey.50' }}>
              <Typography variant="body1" sx={{ lineHeight: 1.6 }}>
                {question.content}
              </Typography>
            </Paper>
          )}
          
          <Paper sx={{ p: 2, mb: 2, backgroundColor: 'info.light' }}>
            <Typography variant="subtitle2" gutterBottom>
              Y√™u c·∫ßu:
            </Typography>
            <Box display="flex" gap={1} flexWrap="wrap">
              {hasPreparationTime && (
                <Chip size="small" label={`Chu·∫©n b·ªã: ${preparationTimeLimit}s`} variant="outlined" />
              )}
              <Chip size="small" label={`Ghi √¢m t·ªëi ƒëa: 30s`} variant="outlined" />
              <Chip size="small" label={`C√≥ th·ªÉ d·ª´ng sau: 10s`} variant="outlined" color="success" />
            </Box>
            {requirements.prompt && (
              <Typography variant="body2" sx={{ mt: 1 }}>
                <strong>Y√™u c·∫ßu:</strong> {requirements.prompt}
              </Typography>
            )}
          </Paper>

          {/* Preparation Timer */}
          {isPreparing && (
            <Paper sx={{ p: 3, mb: 2, textAlign: 'center', backgroundColor: 'warning.light' }}>
              <Typography variant="h3" gutterBottom color="warning.dark">
                {formatTime(preparationTime)}
              </Typography>
              <Typography variant="body1">
                Th·ªùi gian chu·∫©n b·ªã c√≤n l·∫°i
              </Typography>
              <LinearProgress
                variant="determinate"
                value={((preparationTimeLimit - preparationTime) / preparationTimeLimit) * 100}
                sx={{ mt: 2, height: 10, borderRadius: 4 }}
              />
            </Paper>
          )}

          {/* Recording UI */}
          {!isPreparing && (
            <Paper sx={{ p: 3, mb: 2, textAlign: 'center' }}>
              {isUploading && (
                <Box>
                  <Typography variant="h6" gutterBottom color="info.main">
                    üì§ ƒêang t·∫£i l√™n...
                  </Typography>
                  <LinearProgress
                    variant="determinate"
                    value={uploadProgress}
                    sx={{ mb: 2, height: 10, borderRadius: 4 }}
                  />
                  <Typography variant="body2" color="text.secondary">
                    {uploadProgress}% - Vui l√≤ng ch·ªù
                  </Typography>
                </Box>
              )}

              {!isUploading && isRecording && (
                <Box>
                  <Typography variant="h6" gutterBottom>
                    ƒêang ghi √¢m...
                  </Typography>
                  
                  {/* Circular Progress around Microphone */}
                  <Box sx={{ 
                display: 'flex', 
                justifyContent: 'center', 
                alignItems: 'center',
                my: 4,
                position: 'relative',
                width: 320,
                height: 320,
                margin: '30px auto'
              }}>
                {/* Circular Progress Background */}
                <CircularProgress
                  variant="determinate"
                  value={((30 - recordingTime) / 30) * 100}
                  size={280}
                  thickness={4}
                  sx={{
                    color: '#f44336',
                    position: 'absolute'
                  }}
                />
                
                {/* Center content - Microphone and Timer */}
                <Box sx={{
                  display: 'flex',
                  flexDirection: 'column',
                  alignItems: 'center',
                  justifyContent: 'center',
                  zIndex: 1
                }}>
                  {/* Microphone Icon */}
                  <Mic sx={{ 
                    fontSize: 80, 
                    color: '#f44336',
                    mb: 1,
                    animation: 'pulse 1.5s ease-in-out infinite',
                    '@keyframes pulse': {
                      '0%, 100%': { opacity: 1 },
                      '50%': { opacity: 0.5 }
                    }
                  }} />
                  
                  {/* Recording Timer */}
                  <Typography variant="h2" sx={{ 
                    fontWeight: 'bold',
                    color: '#f44336',
                    lineHeight: 1,
                    mt: 1,
                    fontSize: '48px'
                  }}>
                    {formatTime(recordingTime)}
                  </Typography>
                  
                  {/* Recording indicator */}
                  <Typography variant="caption" sx={{ 
                    mt: 2,
                    color: '#666',
                    textAlign: 'center'
                  }}>
                    ƒêang ghi √¢m
                  </Typography>
                </Box>
              </Box>

                  {/* Stop Recording Status */}
                  <Box sx={{ textAlign: 'center', mb: 3 }}>
                    {canStopRecording ? (
                      <Box>
                        <Typography variant="body2" color="success.main" sx={{ mb: 2, fontWeight: 'bold' }}>
                          ‚úì B·∫°n c√≥ th·ªÉ d·ª´ng b√¢y gi·ªù (ƒë√£ ghi ‚â•10 gi√¢y)
                        </Typography>
                        <Button 
                          variant="contained" 
                          color="error"
                          onClick={() => setShowStopConfirmation(true)}
                          startIcon={<Stop />}
                          size="large"
                          sx={{ 
                            fontSize: '16px',
                            py: 2,
                            px: 4
                          }}
                        >
                          D·ª™NG THU √ÇM
                        </Button>
                      </Box>
                    ) : (
                      <Box>
                        <Typography variant="caption" color="error.main" sx={{ fontWeight: 'bold' }}>
                          ‚è≥ Vui l√≤ng ghi √¢m √≠t nh·∫•t 10 gi√¢y tr∆∞·ªõc khi d·ª´ng
                        </Typography>
                        <Typography variant="caption" display="block" sx={{ mt: 1, color: 'text.secondary' }}>
                          C√≤n l·∫°i: {Math.ceil((30 - recordingTime) / 1)} gi√¢y
                        </Typography>
                      </Box>
                    )}
                  </Box>

                  {/* Auto-stop info */}
                  <Typography variant="caption" color="text.secondary" sx={{ display: 'block', textAlign: 'center' }}>
                    H·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông d·ª´ng khi h·∫øt th·ªùi gian
                  </Typography>
                </Box>
              )}

              {!isRecording && !isUploading && !audioBlob && (
                <Box sx={{ textAlign: 'center' }}>
                  <Typography variant="body1" gutterBottom>
                    S·∫µn s√†ng ƒë·ªÉ ghi √¢m?
                  </Typography>
                  <Button 
                    variant="contained" 
                    color="primary"
                    onClick={startRecording}
                    startIcon={<Mic />}
                    size="large"
                    sx={{ 
                      fontSize: '16px',
                      py: 2,
                      px: 4
                    }}
                  >
                    B·∫ÆT ƒê·∫¶U GHI √ÇM
                  </Button>
                </Box>
              )}
            </Paper>
          )}

          {/* Tips */}
          <Paper sx={{ p: 2, backgroundColor: 'grey.50' }}>
            <Typography variant="subtitle2" gutterBottom>
              G·ª£i √Ω n√≥i:
            </Typography>
            <Typography variant="body2" component="ul" sx={{ pl: 2, m: 0 }}>
              <li>N√≥i r√µ r√†ng v√† v·ªõi t·ªëc ƒë·ªô v·ª´a ph·∫£i</li>
              <li>S·ª≠ d·ª•ng th·ªùi gian chu·∫©n b·ªã ƒë·ªÉ l√™n d√†n √Ω</li>
              <li>Tr·∫£ l·ªùi ƒë√∫ng tr·ªçng t√¢m c√¢u h·ªèi</li>
              <li>S·ª≠ d·ª•ng t·ª´ v·ª±ng v√† c·∫•u tr√∫c ƒëa d·∫°ng</li>
            </Typography>
          </Paper>
        </Box>
      )}

      {/* Stop Recording Confirmation Dialog */}
      <Dialog
        open={showStopConfirmation}
        onClose={() => setShowStopConfirmation(false)}
        maxWidth="sm"
        fullWidth
      >
        <DialogTitle sx={{ fontWeight: 'bold', textAlign: 'center' }}>
          X√°c nh·∫≠n d·ª´ng ghi √¢m?
        </DialogTitle>
        <DialogContent>
          <Typography variant="body1" paragraph sx={{ mt: 2, textAlign: 'center' }}>
            B·∫°n c√≥ ch·∫Øc mu·ªën d·ª´ng ghi √¢m l√∫c n√†y kh√¥ng?
          </Typography>
          <Typography variant="body2" color="text.secondary" sx={{ textAlign: 'center' }}>
            T·ªïng th·ªùi gian ghi √¢m: {formatTime(30 - recordingTime)}
          </Typography>
        </DialogContent>
        <DialogActions sx={{ justifyContent: 'center', gap: 2, pb: 2 }}>
          <Button 
            variant="outlined"
            onClick={() => setShowStopConfirmation(false)}
            sx={{ px: 4 }}
          >
            Ti·∫øp t·ª•c ghi √¢m
          </Button>
          <Button 
            variant="contained"
            color="error"
            onClick={confirmStopRecording}
            sx={{ px: 4 }}
          >
            D·ª´ng l·∫°i
          </Button>
        </DialogActions>
      </Dialog>
    </Box>
  );
}